{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score: 0.811\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_pandas import DataFrameMapper, gen_features\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, KBinsDiscretizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from IPython.display import FileLink, FileLinks\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "WEB = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Tree-Ensembles/master/data/tanzania/'\n",
    "source = WEB\n",
    "\n",
    "train = pd.merge(pd.read_csv(source + 'train_features.csv'),\n",
    "                 pd.read_csv(source + 'train_labels.csv'))\n",
    "\n",
    "test = pd.read_csv(source + 'test_features.csv')\n",
    "sample_submission = pd.read_csv(source + 'sample_submission.csv')\n",
    "\n",
    "train, val = train_test_split(train, train_size = 0.80, test_size = 0.20,\n",
    "                             stratify = train['status_group'], random_state = 42)\n",
    "\n",
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format = True)\n",
    "    X['year_recorded'] = X['date_recorded'].dt.year\n",
    "    X['month_recorded'] = X['date_recorded'].dt.month\n",
    "    X['day_recorded'] = X['date_recorded'].dt.day\n",
    "    X = X.drop(columns = 'date_recorded')\n",
    "    X['years'] = X['year_recorded'] - X['construction_year']\n",
    "    X.drop(columns = ['recorded_by', 'id'])\n",
    "    duplicate_columns = ['quantity_group']\n",
    "    X = X.drop(columns = duplicate_columns)\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, np.nan)\n",
    "    cols_with_zeros = ['construction_year', 'longitude', 'latitude', 'gps_height', 'population']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "    return X\n",
    "\n",
    "train = wrangle(train)\n",
    "val = wrangle(val)\n",
    "test = wrangle(test)   \n",
    "\n",
    "target = 'status_group'\n",
    "train_features = train.drop(columns = [target])\n",
    "features = train_features.columns.tolist()\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    SimpleImputer(strategy = 'mean'),\n",
    "    RandomForestClassifier(n_estimators = 100,\n",
    "                          n_jobs = -1)\n",
    ")\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(f'Validation Score: {pipeline.score(X_val, y_val):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_pandas import DataFrameMapper, gen_features\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, KBinsDiscretizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from IPython.display import FileLink, FileLinks\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEB = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Tree-Ensembles/master/data/tanzania/'\n",
    "source = WEB\n",
    "\n",
    "train = pd.merge(pd.read_csv(source + 'train_features.csv'),\n",
    "                 pd.read_csv(source + 'train_labels.csv'))\n",
    "\n",
    "test = pd.read_csv(source + 'test_features.csv')\n",
    "sample_submission = pd.read_csv(source + 'sample_submission.csv')\n",
    "\n",
    "train, val = train_test_split(train, train_size = 0.80, test_size = 0.20,\n",
    "                             stratify = train['status_group'], random_state = 42)\n",
    "\n",
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format = True)\n",
    "    X['year_recorded'] = X['date_recorded'].dt.year\n",
    "    X['month_recorded'] = X['date_recorded'].dt.month\n",
    "    X['day_recorded'] = X['date_recorded'].dt.day\n",
    "    X = X.drop(columns = ['date_recorded', 'id', 'recorded_by'])\n",
    "    X['years'] = X['year_recorded'] - X['construction_year']\n",
    "    duplicate_columns = ['quantity_group']\n",
    "    X = X.drop(columns = duplicate_columns)\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, np.nan)\n",
    "    cols_with_zeros = ['construction_year', 'longitude', 'latitude', 'gps_height', 'population']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "    return X\n",
    "\n",
    "train = wrangle(train)\n",
    "val = wrangle(val)\n",
    "test = wrangle(test)   \n",
    "\n",
    "target = 'status_group'\n",
    "train_features = train.drop(columns = [target])\n",
    "features = train_features.columns.tolist()\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BinaryEncoder = ce.BinaryEncoder\n",
    "OrdinalEncoder = ce.OrdinalEncoder\n",
    "OneHotEncoder = ce.OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_missing_binary = gen_features(\n",
    "    columns = [['funder'], ['installer'], ['scheme_name']],\n",
    "    classes = [{'class': SimpleImputer, 'strategy': 'constant', 'fill_value': 'missing'},\n",
    "               BinaryEncoder]\n",
    ")\n",
    "impute_mean = gen_features(\n",
    "    columns = [['longitude'], ['latitude'], ['gps_height'], ['construction_year'], ['population']],\n",
    "    classes = [{'class': SimpleImputer, 'strategy': 'mean'}]\n",
    ")\n",
    "onehot_encode = gen_features(\n",
    "    columns = [['quantity'], ['waterpoint_type'], ['extraction_type_class'], ['waterpoint_type_group'],\n",
    "              ['extraction_type_group'], ['basin'], ['extraction_type'], ['extraction_type_group'],\n",
    "              ['management'], ['management_group'], ['payment'], ['payment_type'], ['quality_group'],\n",
    "              ['region'], ['source'], ['source_class'], ['source_type'], ['water_quality'],\n",
    "              ['waterpoint_type']],\n",
    "    classes = [OneHotEncoder]\n",
    ")\n",
    "ordinal_encode = gen_features(\n",
    "    columns = [['lga']],\n",
    "    classes = [OrdinalEncoder]\n",
    ")\n",
    "binary_encode = gen_features(\n",
    "    columns = [['wpt_name'], ['subvillage'], ['ward']],\n",
    "    classes = [BinaryEncoder]\n",
    ")\n",
    "no_encode = gen_features(\n",
    "    columns = [['day_recorded'], ['years'], ['amount_tsh'], ['district_code'], ['month_recorded'], \n",
    "              ['num_private'], ['region_code'], ['year_recorded']],\n",
    "    classes = None\n",
    ")\n",
    "\n",
    "mapped_features = (impute_missing_binary + impute_mean + onehot_encode + \n",
    "                  ordinal_encode + binary_encode + no_encode)\n",
    "\n",
    "mapper = DataFrameMapper(mapped_features, df_out = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score: 0.814\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    mapper,\n",
    "    RandomForestClassifier(n_estimators = 100,\n",
    "                          n_jobs = -1)\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(f'Validation Score: {pipeline.score(X_val, y_val):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "./<br>\n",
       "&nbsp;&nbsp;<a href='./random_forests.ipynb' target='_blank'>random_forests.ipynb</a><br>\n",
       "&nbsp;&nbsp;<a href='./random_forests_assignment.ipynb' target='_blank'>random_forests_assignment.ipynb</a><br>\n",
       "&nbsp;&nbsp;<a href='./rgolds-submission-10.csv' target='_blank'>rgolds-submission-10.csv</a><br>\n",
       "&nbsp;&nbsp;<a href='./rgolds-submission-7.csv' target='_blank'>rgolds-submission-7.csv</a><br>\n",
       "&nbsp;&nbsp;<a href='./rgolds-submission-8.csv' target='_blank'>rgolds-submission-8.csv</a><br>\n",
       "&nbsp;&nbsp;<a href='./rgolds-submission-9.csv' target='_blank'>rgolds-submission-9.csv</a><br>\n",
       "&nbsp;&nbsp;<a href='./Untitled.ipynb' target='_blank'>Untitled.ipynb</a><br>\n",
       ".\\.ipynb_checkpoints/<br>\n",
       "&nbsp;&nbsp;<a href='./.ipynb_checkpoints/random_forests-checkpoint.ipynb' target='_blank'>random_forests-checkpoint.ipynb</a><br>\n",
       "&nbsp;&nbsp;<a href='./.ipynb_checkpoints/random_forests_assignment-checkpoint.ipynb' target='_blank'>random_forests_assignment-checkpoint.ipynb</a><br>\n",
       "&nbsp;&nbsp;<a href='./.ipynb_checkpoints/Untitled-checkpoint.ipynb' target='_blank'>Untitled-checkpoint.ipynb</a><br>"
      ],
      "text/plain": [
       "./\n",
       "  random_forests.ipynb\n",
       "  random_forests_assignment.ipynb\n",
       "  rgolds-submission-10.csv\n",
       "  rgolds-submission-7.csv\n",
       "  rgolds-submission-8.csv\n",
       "  rgolds-submission-9.csv\n",
       "  Untitled.ipynb\n",
       ".\\.ipynb_checkpoints/\n",
       "  random_forests-checkpoint.ipynb\n",
       "  random_forests_assignment-checkpoint.ipynb\n",
       "  Untitled-checkpoint.ipynb"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "submission = sample_submission.copy()\n",
    "submission['status_group'] = y_pred\n",
    "submission.to_csv('rgolds-submission-10.csv', index = False)\n",
    "\n",
    "from IPython.display import FileLink, FileLinks\n",
    "FileLinks('.') #lists all downloadable files on server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_impute_features = ['construction_year', 'gps_height', 'latitude', 'longitude', 'population']\n",
    "catimpute_binary_features = ['funder', 'installer', 'scheme_name']\n",
    "catimpute_onehot_features = ['scheme_management']\n",
    "one_hot_features = ['basin', 'extraction_type', 'extraction_type_class', 'extraction_type_group', 'management',\n",
    "                   'management_group', 'payment', 'payment_type', 'quality_group', 'quantity', 'region', \n",
    "                   'source', 'source_class', 'source_type', 'water_quality', \n",
    "                   'waterpoint_type', 'waterpoint_type_group']\n",
    "ordinal_features = ['lga']\n",
    "binary_features = ['subvillage', 'ward', 'wpt_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catimpute_binary_transformer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'constant', fill_value = 'missing')),\n",
    "    ('binary', ce.BinaryEncoder())\n",
    "])\n",
    "catimpute_onehot_transformer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'constant', fill_value = 'missing')),\n",
    "    ('onehot', ce.OneHotEncoder(use_cat_names = True))\n",
    "])\n",
    "num_impute_transformer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'mean'))\n",
    "])\n",
    "one_hot_transformer = Pipeline(steps = [\n",
    "    ('onehot', ce.OneHotEncoder(use_cat_names = True))\n",
    "])\n",
    "ordinal_transformer = Pipeline(steps = [\n",
    "    ('ordinal', ce.OrdinalEncoder())\n",
    "])\n",
    "binary_transformer = Pipeline(steps = [\n",
    "    ('binary', ce.BinaryEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('catimpute_binary', catimpute_binary_transformer, catimpute_binary_features),\n",
    "        ('catimpute_onehot', catimpute_onehot_transformer, catimpute_onehot_features),\n",
    "        ('num_impute', num_impute_transformer, num_impute_features),\n",
    "        ('onehot', one_hot_transformer, one_hot_features),\n",
    "        ('ordinal', ordinal_transformer, ordinal_features),\n",
    "        ('binary', binary_transformer, binary_features)],\n",
    "    remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps = [\n",
    "    ('preprocessor', preprocessor),\n",
    "       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
