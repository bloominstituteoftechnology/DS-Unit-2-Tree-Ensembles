{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC, BorderlineSMOTE, SMOTE\n",
    "\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 41), (14358, 40))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = '../data/tanzania/'\n",
    "\n",
    "# Merge train features and train labels\n",
    "train = pd.merge(pd.read_csv(source + 'train_features.csv'),\n",
    "                 pd.read_csv(source + 'train_labels.csv'))\n",
    "\n",
    "# read test and sample submission\n",
    "test = pd.read_csv(source + 'test_features.csv')\n",
    "sample_sub = pd.read_csv(source + 'sample_submission.csv')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at distribution of target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 0.543081\n",
       "non functional             0.384242\n",
       "functional needs repair    0.072677\n",
       "Name: status_group, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['status_group'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the data into train and valuate sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 41), (11880, 41), (14358, 40))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val = train_test_split(train, \n",
    "                              test_size=0.2, \n",
    "                              stratify=train['status_group'],\n",
    "                             random_state=42)\n",
    "\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data and engineer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data (X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # convert all strings to lowercase\n",
    "    cat_features = X.select_dtypes('object').columns.tolist()\n",
    "    for feat in cat_features:\n",
    "        X[feat] = X[feat].str.lower()\n",
    "        \n",
    "    # Replace -2.00000e-08 with np.nan\n",
    "    X['latitude'] = X['latitude'].replace(-2.000000e-08, np.nan)\n",
    "    \n",
    "    clean_features = [\n",
    "        'gps_height',\n",
    "        'population',\n",
    "        'amount_tsh',\n",
    "        'construction_year',\n",
    "        'latitude',\n",
    "        'longitude'\n",
    "    ]\n",
    "    \n",
    "    for feat in clean_features:\n",
    "        # Replace values=0.0 with np.nan\n",
    "        X[feat] = X[feat].replace(0, np.nan)\n",
    "        \n",
    "        # fill nan with mean using region and district code\n",
    "        X[feat] = X[feat].fillna(X.groupby(['region', 'district_code'])[feat].transform('mean'))\n",
    "        \n",
    "        # fill nan with mean of region if district code is missing\n",
    "        X[feat] = X[feat].fillna(X.groupby(['region'])[feat].transform('mean'))\n",
    "        \n",
    "        # fill nan with general mean if no region or district code\n",
    "        X[feat] = X[feat].fillna(X[feat].mean())\n",
    "        \n",
    "    # fillna of scheme_management with 'unknow' and combine low count values into 'other'\n",
    "    X['scheme_management'] = X['scheme_management'].fillna('unknown')\n",
    "    X['scheme_management'] = X['scheme_management'].replace({\n",
    "        'swc':'Other',\n",
    "        'trust':'Other',\n",
    "        'none':'Other',\n",
    "        'company': 'Other'\n",
    "    })\n",
    "    \n",
    "    # make date_recorded datetime type\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'])\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # create month and year features from date_recorded\n",
    "    X['month'] = X['date_recorded'].dt.month\n",
    "    X['year'] = X['date_recorded'].dt.year\n",
    "    \n",
    "    # create a pump age feature\n",
    "    X['pump_age'] = (X['year'].max() - X['construction_year'])\n",
    "    \n",
    "    # create seasons based on month\n",
    "    X['hot_dry'] = (X['month'] == 12) | (X['month'] < 3)     # Dec. - Feb.\n",
    "    X['cool_dry'] = (X['month'] > 5) & (X['month'] < 11)     # Jun. - Oct\n",
    "    X['light_rain'] = (X['month'] == 3) | (X['month'] == 11) # Mar. & Nov.\n",
    "    X['heavy_rain'] = (X['month'] == 4) | (X['month'] == 5)  # Apr. & May\n",
    "    \n",
    "    # create installer features\n",
    "    X['dwe_installer'] = (X['installer'] == 'dwe')\n",
    "    X['gov_installer'] = (X['installer'] == 'government')\n",
    "     \n",
    "    one_time_installer = X['installer'].value_counts()[X['installer'].value_counts() == 1]\n",
    "    X['one_time_installer'] = X['installer'].isin(one_time_installer.index)\n",
    "    \n",
    "    minor_installer = X['installer'].value_counts()[X['installer'].value_counts() <= 7]\n",
    "    X['minor_installer'] = X['installer'].isin(minor_installer.index)\n",
    "    \n",
    "    major_installer = X['installer'].value_counts()[X['installer'].value_counts() > 7]\n",
    "    X['major_installer'] = X['installer'].isin(major_installer.index)\n",
    "    \n",
    "    # create funder features\n",
    "    X['gov_funder'] = (X['funder'] == 'government of tanzania')\n",
    "     \n",
    "    one_time_funder = X['funder'].value_counts()[X['funder'].value_counts() == 1]\n",
    "    X['one_time_funder'] = X['funder'].isin(one_time_funder.index)\n",
    "    \n",
    "    minor_funder = X['funder'].value_counts()[X['funder'].value_counts() <= 7]\n",
    "    X['minor_funder'] = X['funder'].isin(minor_funder.index)\n",
    "    \n",
    "    major_funder = X['funder'].value_counts()[X['funder'].value_counts() > 7]\n",
    "    X['major_funder'] = X['funder'].isin(major_funder.index)\n",
    "    \n",
    "    # amount per person \n",
    "    X['amount_per_person'] = (X['amount_tsh'] / X['population'])\n",
    "    \n",
    "    # gps height / ampunt\n",
    "    X['gps_per_person'] = X['gps_height'] / X['amount_tsh']\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # drop unneeded cols\n",
    "    drop_cols = [\n",
    "        'recorded_by',\n",
    "        'id',\n",
    "        'quantity_group',\n",
    "        'public_meeting',\n",
    "        'permit',\n",
    "        'date_recorded'\n",
    "    ]\n",
    "    \n",
    "    X = X.drop(columns=drop_cols)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean data using function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 41), (11880, 41), (14358, 40))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = clean_data(train)\n",
    "val = clean_data(val)\n",
    "test = clean_data(test)\n",
    "\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature engineering with function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 59), (11880, 59), (14358, 58))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = feature_eng(train)\n",
    "val = feature_eng(val)\n",
    "test = feature_eng(test)\n",
    "\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop columns that are not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 53), (11880, 53), (14358, 52))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = drop_cols(train)\n",
    "val = drop_cols(val)\n",
    "test = drop_cols(test)\n",
    "\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into X features and Y target for train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The status_group column is the target\n",
    "target = 'status_group'\n",
    "\n",
    "# Get a dataframe with all train columns except the target\n",
    "train_features = train.drop(columns=[target])\n",
    "\n",
    "# Get a list of the numeric features\n",
    "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Get a series with the cardinality of the nonnumeric features\n",
    "cardinality = train_features.select_dtypes(exclude='number').nunique()\n",
    "\n",
    "# Get a list of all categorical features with cardinality <= 50\n",
    "categorical_features = cardinality[cardinality <= 1000].index.tolist()\n",
    "\n",
    "# Combine the lists \n",
    "features = numeric_features + categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 46), (47520,), (11880, 46), (11880,), (14358, 46))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "\n",
    "X_test = test[features]\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try SMOTE to over sample minority class before running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
    "\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_val = encoder.transform(X_val)\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 312), (11880, 312), (14358, 312))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((69873, 312), (69873,))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oversample using SMOTE to boost needs repair class\n",
    "smote = SMOTE('minority')\n",
    "\n",
    "X_train_sm, y_train_sm = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "X_train_sm.shape, y_train_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 0.369342\n",
       "functional needs repair    0.369342\n",
       "non functional             0.261317\n",
       "dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train_sm).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=500,\n",
    "                           random_state=42, \n",
    "                           n_jobs=-1)\n",
    "\n",
    "clf_rf.fit(X_train_sm, y_train_sm)\n",
    "clf_rf.score(X_val, y_val)\n",
    "\n",
    "y_pred = clf_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [11880, 14358]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-166-8e9d104df662>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [11880, 14358]"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
