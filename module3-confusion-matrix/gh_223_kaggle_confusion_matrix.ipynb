{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gh_223_kaggle_confusion_matrix.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P_XjBTW5SBwZ"
      },
      "source": [
        "# Assignment\n",
        "- Read [Maximizing Scarce Maintenance Resources with Data: Applying predictive modeling, precision at k, and clustering to optimize impact](https://towardsdatascience.com/maximizing-scarce-maintenance-resources-with-data-8f3491133050), by Lambda DS3 student Michael Brady. His blog post extends the Tanzania Waterpumps scenario, far beyond what's in this lecture notebook.\n",
        "\n",
        "If your Kaggle Public Leaderboard score is:\n",
        "- **Nonexistent**: You need to work on your model and submit predictions\n",
        "- **< 70%**: You should work on your model and submit predictions\n",
        "- **70% < score < 80%**: You may want to work on visualizations and write a blog post\n",
        "- **> 80%**: You should work on visualizations and write a blog post\n",
        "\n",
        "\n",
        "## Stretch goals — Highly Recommended Links\n",
        "- Read Google Research's blog post, [Attacking discrimination with smarter machine learning](https://research.google.com/bigpicture/attacking-discrimination-in-ml/), and explore the interactive visualizations. _\"A threshold classifier essentially makes a yes/no decision, putting things in one category or another. We look at how these classifiers work, ways they can potentially be unfair, and how you might turn an unfair classifier into a fairer one. As an illustrative example, we focus on loan granting scenarios where a bank may grant or deny a loan based on a single, automatically computed number such as a credit score.\"_\n",
        "- Read the blog post, [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415). You can replicate the code as-is,  [\"the hard way\"](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit). Or you can apply it to the Tanzania Waterpumps data.\n",
        "- Read this [notebook about how to calculate expected value from a confusion matrix by treating it as a cost-benefit matrix](https://github.com/podopie/DAT18NYC/blob/master/classes/13-expected_value_cost_benefit_analysis.ipynb).\n",
        "- (Re)read the [Simple guide to confusion matrix terminology](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) and watch the 35 minute video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBV7oSfMtINs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "8102a6ed-9a0c-4ea0-d61e-ca96c1f0e309"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/a1/f7a22f144f33be78afeb06bfa78478e8284a64263a3c09b1ef54e673841e/category_encoders-2.0.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.21.2)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.3.0)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.13.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un6ZHytatYP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install category_encoders matplotlib==3.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEcRawLGtcR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import category_encoders as ce\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uOHk1YXtnqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOCAL = '../data/tanzania/'\n",
        "WEB = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Tree-Ensembles/master/data/tanzania/'\n",
        "source = WEB\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv(source + 'train_features.csv'), \n",
        "                 pd.read_csv(source + 'train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv(source + 'test_features.csv')\n",
        "sample_submission = pd.read_csv(source + 'sample_submission.csv')\n",
        "\n",
        "# Split train into train & val. Make val the same size as test.\n",
        "train, val = train_test_split(train, test_size=len(test),  \n",
        "                              stratify=train['status_group'], random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiJbuUNptpTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrangle(X):\n",
        "    \"\"\"Wrangles train, validate, and test sets in the same way\"\"\"\n",
        "    X = X.copy()\n",
        "\n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']    \n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Drop duplicate columns\n",
        "    duplicate_columns = ['quantity_group']\n",
        "    X = X.drop(columns=duplicate_columns)\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these like null values\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, np.nan)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values\n",
        "    cols_with_zeros = ['construction_year', 'longitude', 'latitude', 'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "    \n",
        "    X['dwe'] = (X['installer']=='DWE')&(X['funder']=='Dwe')\n",
        "    X['gov_install_fund'] = (X['installer']=='Government')&(X['funder']=='Government Of Tanzania')\n",
        "    X['gov'] = (X['installer']=='Government')&(X['funder']=='Government Of Tanzania')&(X['scheme_name']=='Government')\n",
        "    X['vwc_management'] = (X['management']=='vwc')&(X['scheme_management']=='VWC')\n",
        "    X['gravity_extraction'] = (X['extraction_type']=='gravity')&(X['extraction_type_group']=='gravity')&(X['extraction_type_class']=='gravity')\n",
        "    \n",
        "    return X\n",
        "\n",
        "# Wrangle train, validate, and test sets in the same way\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcctPqCkt-GU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6c0d3bd-3d6a-48af-ee52-70d1aa0dca86"
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "target = 'status_group'\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "X_test = test\n",
        "\n",
        "# Make pipeline!\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='mean'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_val)\n",
        "val_score = accuracy_score(y_val, y_pred)\n",
        "print('Validation Accuracy', val_score*100)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 81.40409527789386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuCoThgOuMx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get feature importances\n",
        "rf = pipeline.named_steps['randomforestclassifier']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cby7iNf1wMmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "35e523fd-0a4f-4046-9156-b3f8c3aac341"
      },
      "source": [
        "importances.index"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['amount_tsh', 'funder', 'gps_height', 'installer', 'longitude',\n",
              "       'latitude', 'wpt_name', 'num_private', 'basin', 'subvillage', 'region',\n",
              "       'region_code', 'district_code', 'lga', 'ward', 'population',\n",
              "       'public_meeting', 'scheme_management', 'scheme_name', 'permit',\n",
              "       'construction_year', 'extraction_type', 'extraction_type_group',\n",
              "       'extraction_type_class', 'management', 'management_group', 'payment',\n",
              "       'payment_type', 'water_quality', 'quality_group', 'quantity', 'source',\n",
              "       'source_type', 'source_class', 'waterpoint_type',\n",
              "       'waterpoint_type_group', 'year_recorded', 'month_recorded',\n",
              "       'day_recorded', 'years'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqSTrG5AwjCx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f0cfe483-52ab-4fa5-f04d-f604259f2c7f"
      },
      "source": [
        "X_train.columns"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['amount_tsh', 'funder', 'gps_height', 'installer', 'longitude',\n",
              "       'latitude', 'wpt_name', 'num_private', 'basin', 'subvillage', 'region',\n",
              "       'region_code', 'district_code', 'lga', 'ward', 'population',\n",
              "       'public_meeting', 'scheme_management', 'scheme_name', 'permit',\n",
              "       'construction_year', 'extraction_type', 'extraction_type_group',\n",
              "       'extraction_type_class', 'management', 'management_group', 'payment',\n",
              "       'payment_type', 'water_quality', 'quality_group', 'quantity', 'source',\n",
              "       'source_type', 'source_class', 'waterpoint_type',\n",
              "       'waterpoint_type_group', 'year_recorded', 'month_recorded',\n",
              "       'day_recorded', 'years'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9okDPpZyhTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_drop = X_train.columns.copy()\n",
        "f_drop.drop(columns='quantity')\n",
        "f_drop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BU7T490uIav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "d9a668d4-53ca-4f6e-d95f-f16a04b39c45"
      },
      "source": [
        "new_f_score = []\n",
        "target = 'status_group'\n",
        "# new_f = importances.sort_values().index.tolist()\n",
        "for feature in X_train.columns:  \n",
        "  pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='mean'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "  )\n",
        "  \n",
        "  X_train_subset = train.drop(columns=[target, feature])\n",
        "  X_val_subset = val.drop(columns=[target, feature])\n",
        "\n",
        "  pipeline.fit(X_train_subset, y_train)\n",
        "  y_pred = pipeline.predict(X_val_subset)\n",
        "  print(feature, accuracy_score(y_val, y_pred)*100)\n",
        "  if accuracy_score(y_val, y_pred) > val_score:\n",
        "    val_score = accuracy_score(y_val, y_pred)\n",
        "    new_f_score = [x, val_score]\n",
        "new_f_score"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "amount_tsh 81.03496308678089\n",
            "funder 81.24390583646748\n",
            "gps_height 81.00013929516646\n",
            "installer 81.06978687839532\n",
            "longitude 80.81209082044853\n",
            "latitude 80.9792450201978\n",
            "wpt_name 81.04889260342667\n",
            "num_private 81.20908204485305\n",
            "basin 80.93745647026049\n",
            "subvillage 81.22301156149881\n",
            "region 81.02103357013512\n",
            "region_code 81.1881877698844\n",
            "district_code 81.04192784510377\n",
            "lga 81.09764591168687\n",
            "ward 81.15336397826995\n",
            "population 80.63100710405348\n",
            "public_meeting 81.04889260342667\n",
            "scheme_management 80.98620977852069\n",
            "scheme_name 81.06978687839532\n",
            "permit 80.93049171193759\n",
            "construction_year 81.0767516367182\n",
            "extraction_type 81.06282212007243\n",
            "extraction_type_group 81.11854018665552\n",
            "extraction_type_class 80.98620977852069\n",
            "management 80.93745647026049\n",
            "management_group 81.17425825323862\n",
            "payment 81.1881877698844\n",
            "payment_type 81.1881877698844\n",
            "water_quality 81.2856943864048\n",
            "quality_group 81.25087059479036\n",
            "quantity 77.86599804986767\n",
            "source 81.14639921994706\n",
            "source_type 80.89566792032316\n",
            "source_class 81.0837163950411\n",
            "waterpoint_type 80.90959743696894\n",
            "waterpoint_type_group 80.99317453684357\n",
            "year_recorded 80.90959743696894\n",
            "month_recorded 81.16032873659283\n",
            "day_recorded 80.95138598690626\n",
            "years 81.04889260342667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsJPKVM70Z8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "32053763-4e7a-4764-b099-efedc76be010"
      },
      "source": [
        "new_f_score = []\n",
        "target = 'status_group'\n",
        "# new_f = importances.sort_values().index.tolist()\n",
        "for x in range(30,len(X_train.columns)+1):  \n",
        "  pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='mean'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "  )\n",
        "  \n",
        "  features = importances[-x:].index.tolist()\n",
        "  \n",
        "  X_train_subset = train[features]\n",
        "  X_val_subset = val[features]\n",
        "  y_train = train[target]\n",
        "  y_val = val[target]\n",
        "  \n",
        "  pipeline.fit(X_train_subset, y_train)\n",
        "  y_pred = pipeline.predict(X_val_subset)\n",
        "  print(x, accuracy_score(y_val, y_pred)*100)\n",
        "  if accuracy_score(y_val, y_pred) > val_score:\n",
        "    val_score = accuracy_score(y_val, y_pred)\n",
        "    new_f_score = [x, val_score]\n",
        "new_f_score"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30 79.95542554673352\n",
            "31 79.87184844685889\n",
            "32 80.10168547151414\n",
            "33 80.08079119654548\n",
            "34 80.08775595486837\n",
            "35 80.63797186237638\n",
            "36 80.6240423457306\n",
            "37 80.721548962251\n",
            "38 80.83994985374008\n",
            "39 81.03496308678089\n",
            "40 81.40409527789386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5gi6SUiwFGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba362543-8128-4ccf-b70e-84715de0d065"
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "target = 'status_group'\n",
        "features = importances[-40:].index.tolist()\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "X_test = test\n",
        "\n",
        "# Make pipeline!\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='mean'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_val)\n",
        "val_score = accuracy_score(y_val, y_pred)\n",
        "print('Validation Accuracy', val_score*100)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 81.40409527789386\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
