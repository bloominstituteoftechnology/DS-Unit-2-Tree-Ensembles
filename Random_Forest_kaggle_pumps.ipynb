{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random-Forest-kaggle-pumps.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjh09/DS-Unit-2-Tree-Ensembles/blob/master/Random_Forest_kaggle_pumps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W7tKhAuRAJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7d98b378-470a-4460-d9f5-8544aec1ae42"
      },
      "source": [
        "!pip install Category_encoders"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Category_encoders in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from Category_encoders) (1.16.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from Category_encoders) (0.21.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from Category_encoders) (1.3.0)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from Category_encoders) (0.24.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from Category_encoders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from Category_encoders) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->Category_encoders) (0.13.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->Category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->Category_encoders) (2.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->Category_encoders) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44AeONNdRixl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i73m14UR2Gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Tree-Ensembles/master/data/tanzania/'\n",
        "\n",
        "train = pd.merge(pd.read_csv(path + 'train_features.csv'),\n",
        "                 pd.read_csv(path + 'train_labels.csv'))\n",
        "\n",
        "test = pd.read_csv(path + 'test_features.csv')\n",
        "sample_submission = pd.read_csv(path + 'sample_submission.csv')\n",
        "\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20,\n",
        "                             stratify=train['status_group'], random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTKQ2zObVETt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrangle(X):\n",
        "  # \" Wrangles train, validate, and test sets in the same way\"\n",
        "  X = X.copy()\n",
        "  \n",
        "  # Convert date_recorded to datetime\n",
        "  X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "  \n",
        "  # Extract components from date_recored, then drop the original column\n",
        "  X['year_recorded'] = X['date_recorded'].dt.year\n",
        "  X['month_recorded'] = X['date_recorded'].dt.month\n",
        "  X['day_recorded'] = X['date_recorded'].dt.day\n",
        "  X = X.drop(columns='date_recorded')\n",
        "  \n",
        "  # Engineer feature: how many years from construction_year to date_recorded\n",
        "  X['years'] = X['year_recorded'] - X['construction_year']\n",
        "  \n",
        "  # Drop recorded by (never varies) and id (always varies, random)\n",
        "  X = X.drop(columns=['recorded_by', 'id'])\n",
        "  \n",
        "  # Drop duplicate columns\n",
        "  duplicate_columns = ['quantity_group']\n",
        "  X = X.drop(columns=duplicate_columns)\n",
        "  \n",
        "  # About 3% of the time, latitude has small values near zero,\n",
        "  # outside Tanzania, so we'll treat these like null values\n",
        "  X['latitude'] = X['latitude'].replace(-2e-08, np.nan)\n",
        "  \n",
        "  # When columns have zeros and shouldn't, they are like null values\n",
        "  cols_with_zeros = ['construction_year', 'longitude', 'latitude', 'gps_height', 'population']\n",
        "  for col in cols_with_zeros:\n",
        "    X[col] = X[col].replace(0, np.nan)\n",
        "    \n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_CIRHQcZfzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTAkSUaDd3Qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The status_group column is the target\n",
        "target = 'status_group'\n",
        "\n",
        "# Get a dataframe with all train columns except the target\n",
        "train_features = train.drop(columns=[target])\n",
        "\n",
        "# Get a list of the numeric features\n",
        "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "# Get a series with the cardinality of the nonnumeric features\n",
        "cardinality = train_features.select_dtypes(exclude='number').nunique()\n",
        "\n",
        "# Get a list of all categorical features with cardinality <= 50\n",
        "categorical_features = cardinality[cardinality <= 50].index.tolist()\n",
        "\n",
        "# combine the lists\n",
        "features = numeric_features + categorical_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q9og9vXcc1h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "cb1895c0-ab13-40b6-a0e7-b16fed877eff"
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "X_test = test[features]\n",
        "\n",
        "# Make pipeline\n",
        "pipeline = make_pipeline(ce.OrdinalEncoder(),\n",
        "                         SimpleImputer(strategy='median'),\n",
        "                         RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
        "\n",
        "# Fit on train, score on validation, predict on test\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# write submission to csv file\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "submission.to_csv('random-forest-model.csv', index=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8106902356902357\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}