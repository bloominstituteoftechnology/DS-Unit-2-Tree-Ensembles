{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Pumps.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jWodqzTT3dX",
        "colab_type": "text"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAkmooj0wHc4",
        "colab_type": "code",
        "outputId": "ba5331a0-41d0-4e05-aa4b-c93264b9b0ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!pip install pandas_profiling\n",
        "!pip install category_encoders"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas_profiling in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from pandas_profiling) (1.12.0)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from pandas_profiling) (0.24.2)\n",
            "Requirement already satisfied: matplotlib>=1.4 in /usr/local/lib/python3.6/dist-packages (from pandas_profiling) (3.0.3)\n",
            "Requirement already satisfied: jinja2>=2.8 in /usr/local/lib/python3.6/dist-packages (from pandas_profiling) (2.10.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pandas_profiling) (1.16.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pandas_profiling) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pandas_profiling) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas_profiling) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas_profiling) (2.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas_profiling) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.8->pandas_profiling) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4->pandas_profiling) (41.0.1)\n",
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.21.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g6nuHjwwHc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import category_encoders as ce\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnBigpDQwHc-",
        "colab_type": "code",
        "outputId": "1809af83-1af3-4043-c0a5-00ea398cda7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/tanzania/train_features.csv\n",
        "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/tanzania/train_labels.csv\n",
        "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/tanzania/test_features.csv\n",
        "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/tanzania/sample_submission.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-23 19:10:52--  https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/tanzania/train_features.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20054664 (19M) [text/plain]\n",
            "Saving to: ‘train_features.csv.2’\n",
            "\n",
            "train_features.csv. 100%[===================>]  19.12M   117MB/s    in 0.2s    \n",
            "\n",
            "2019-07-23 19:10:53 (117 MB/s) - ‘train_features.csv.2’ saved [20054664/20054664]\n",
            "\n",
            "--2019-07-23 19:10:53--  https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/tanzania/train_labels.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1148327 (1.1M) [text/plain]\n",
            "Saving to: ‘train_labels.csv.2’\n",
            "\n",
            "train_labels.csv.2  100%[===================>]   1.09M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2019-07-23 19:10:54 (14.2 MB/s) - ‘train_labels.csv.2’ saved [1148327/1148327]\n",
            "\n",
            "--2019-07-23 19:10:54--  https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/tanzania/test_features.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4851589 (4.6M) [text/plain]\n",
            "Saving to: ‘test_features.csv.2’\n",
            "\n",
            "test_features.csv.2 100%[===================>]   4.63M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-07-23 19:10:54 (41.3 MB/s) - ‘test_features.csv.2’ saved [4851589/4851589]\n",
            "\n",
            "--2019-07-23 19:10:55--  https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/tanzania/sample_submission.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 241972 (236K) [text/plain]\n",
            "Saving to: ‘sample_submission.csv.2’\n",
            "\n",
            "sample_submission.c 100%[===================>] 236.30K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-07-23 19:10:55 (4.58 MB/s) - ‘sample_submission.csv.2’ saved [241972/241972]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBIW2d0pwHdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas_profiling as pp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9aIaK0Qg2gi",
        "colab_type": "text"
      },
      "source": [
        "##Fetch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdC1VpD9wHdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load dataframes\n",
        "X = pd.read_csv('train_features.csv')\n",
        "Y = pd.read_csv('train_labels.csv')\n",
        "\n",
        "#Drop id's\n",
        "Y = Y.status_group"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWBsgbdDwHdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pp.ProfileReport(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GETGuxjVT_LW",
        "colab_type": "text"
      },
      "source": [
        "##Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOEuOaWewHdc",
        "colab_type": "code",
        "outputId": "16adc4d9-a3b5-48a0-b8e9-fba65464e8df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#Split data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, Y,random_state = 42,stratify = Y)\n",
        "    \n",
        "#Baseline\n",
        "y_train.value_counts(normalize = True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "functional                 0.543075\n",
              "non functional             0.384242\n",
              "functional needs repair    0.072682\n",
              "Name: status_group, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai-vFkvzwHdg",
        "colab_type": "code",
        "outputId": "ed47e020-7830-4db1-c386-eca3b3161ef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#get nums from df\n",
        "numericals = X.select_dtypes('number').columns.to_list()\n",
        "print(numericals)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['id', 'amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private', 'region_code', 'district_code', 'population', 'construction_year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlPcqfpKwHdk",
        "colab_type": "code",
        "outputId": "d4eab390-326a-4ff7-a431-2f7c4f817ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "model = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', max_iter = 350)\n",
        "model.fit(X_train[numericals],y_train)\n",
        "model.score(X_val[numericals], y_val)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5484848484848485"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOmHy4CtwHdp",
        "colab_type": "code",
        "outputId": "e31d048e-59c9-4086-ff53-2bef3416f7af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#plot coefficent values for each label\n",
        "fig = plt.figure(figsize = (30,5), )\n",
        "\n",
        "ax = fig.add_subplot(131)\n",
        "coeffs = pd.Series(model.coef_[0], numericals)\n",
        "ax = coeffs.sort_values().plot.barh()\n",
        "ax.set_title(model.classes_[0], color = 'g')\n",
        "\n",
        "ax1 = fig.add_subplot(132)\n",
        "coeffs = pd.Series(model.coef_[1], numericals)\n",
        "ax1 = coeffs.sort_values().plot.barh()\n",
        "ax1.set_title(model.classes_[1], color = 'y')\n",
        "\n",
        "ax2 = fig.add_subplot(133)\n",
        "coeffs = pd.Series(model.coef_[2], numericals)\n",
        "ax2 = coeffs.sort_values().plot.barh()\n",
        "ax2.set_title(model.classes_[2], color = 'r')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'non functional')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSoJ0sY9TpGI",
        "colab_type": "text"
      },
      "source": [
        "It looks like longitude and region code have some of the largest effects on the model based on the coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNVfUAwgXSLE",
        "colab_type": "text"
      },
      "source": [
        "##Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCigo0fC9JKL",
        "colab_type": "code",
        "outputId": "92358c89-592f-4cfc-d07d-772fd06dd27c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Check if there are any coordinates in data that are outside of tanzania\n",
        "\n",
        "#28 is west most and 42 is east most boundary  \n",
        "print(X[(X.longitude <28) | (X.longitude > 42)].shape[0])\n",
        "\n",
        "#0 is top most and -12 is lowest boundary\n",
        "print(X[(X.latitude > 0) | (X.latitude < -12)].shape[0]) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1812\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq7Gu4EumoGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_elevations(x):\n",
        "#store each region and gps height in dict\n",
        "  elevations = {}\n",
        "  for region in x.region.unique():\n",
        "    elevations[region] = x[x.region == region]['gps_height'].median()\n",
        "\n",
        "#These looks to be the problem areas. The median values for these regions should not be zeo\n",
        "  zero_regions = ['Dodoma', 'Kagera', 'Mbeya', 'Mwanza', 'Shinyanga', 'Tabora']\n",
        "\n",
        "#I looked up the elevations and imputed the data\n",
        "  elevations['Dodoma'] = 1118\n",
        "  elevations['Kagera'] = 1500\n",
        "  elevations['Mbeya'] = 1700\n",
        "  elevations['Mwanza'] = 1140\n",
        "  elevations['Shinyanga'] = 1128\n",
        "  elevations['Tabora'] = 1191\n",
        "\n",
        "#Use new values to clean zeroes in df based on imputed values\n",
        "  for key in elevations:\n",
        "    if key in zero_regions:\n",
        "      x.loc[x.region == key, 'gps_height'] = elevations[key]\n",
        "  \n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU5Ijk3aYpf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dates(x):\n",
        "  #reassgin as datetime object\n",
        "  x.date_recorded = pd.to_datetime(x.date_recorded,\n",
        "                                   infer_datetime_format= True)\n",
        "  \n",
        "  #split values and add to df\n",
        "  x['year'] = x.date_recorded.dt.year\n",
        "  x['month'] = x.date_recorded.dt.month\n",
        "  x['day_of_week'] = x.date_recorded.dt.dayofweek\n",
        "  \n",
        "  #drop dates(not working with standard scaler?)\n",
        "  x = x.drop('date_recorded', axis = 1)\n",
        "  \n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgq4RUvzXTQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(df):\n",
        "  x = df\n",
        "  \n",
        "#Clean zeroes, I will infer zero equate to missing data that cant be imputed\n",
        "  zeroes = ['construction_year', 'longitude', 'population']\n",
        "  for col in zeroes:\n",
        "    x[col] = x[col].replace(0, np.nan)  \n",
        "\n",
        "#eliminate null island values\n",
        "  x['latitude'] = x['latitude'].replace(-2e-08, np.nan)\n",
        "  x['longitude'] = x['longitude'].replace(-2e-08, np.nan)\n",
        "\n",
        "#For consistency, replace latitude values with NaN where longitude contains NaN\n",
        "  x['latitude'] = np.where(x.longitude.isnull(), np.NaN, x.latitude)\n",
        "  \n",
        "#reassign date values\n",
        "  x = get_dates(x)\n",
        "  \n",
        "#impute gps data\n",
        "  x = get_elevations(x)\n",
        "\n",
        "#drop items both high card and duplicates\n",
        "  dropping = ['quantity_group', 'recorded_by','subvillage', 'wpt_name',\n",
        "              'management_group']  \n",
        "  x = x.drop(dropping, axis = 1)\n",
        "\n",
        "#reassign bool values\n",
        "  x['permit'] = np.where(x.permit == True , 1,0)\n",
        "  x['public_meeting'] = np.where(x.public_meeting == True , 1,0)\n",
        "\n",
        "  return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfj-Xk7v0zbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clean, encode, and scale data\n",
        "def transform(df):\n",
        "  X = clean(df)\n",
        "  \n",
        "    #encode objects\n",
        "  for col in X.select_dtypes('object').columns.tolist():\n",
        "    #One hot encode low card data\n",
        "    if len(X[col].unique()) <=10:\n",
        "      encode = ce.OneHotEncoder()\n",
        "      X = X.join(encode.fit_transform(X[col].astype('str')))\n",
        "      X = X.drop(col, axis = 1)\n",
        "    #Label encode high card data  \n",
        "    else:\n",
        "      le = LabelEncoder()\n",
        "      X[col] = le.fit_transform(X[col].astype('str')) \n",
        "\n",
        "  #Scale data\n",
        "  X = StandardScaler().fit_transform(X)\n",
        "  \n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0IEgcZ31UyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dropNA(X, **kwargs):\n",
        "  #if a target vector is supplied, store a copy in Y\n",
        "  if 'y' in kwargs:\n",
        "    Y = kwargs['y'].copy()\n",
        "    \n",
        "    #Combine data for a consistent drop\n",
        "    X = X.join(Y)\n",
        "\n",
        "    #drop NANs\n",
        "    X = X.dropna()\n",
        "\n",
        "    #Split data\n",
        "    Y = X.pop('status_group')\n",
        "  \n",
        "    return X,Y\n",
        "  else:\n",
        "    X = X.dropna()\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz25KEvrHA6E",
        "colab_type": "text"
      },
      "source": [
        "##Preprocessing & Preliminary Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rza9KPkGlbw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(X,Y):  \n",
        "  #Split data\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X, Y,\n",
        "                                              random_state = 42,stratify = Y)\n",
        "  \n",
        "  return [X_train, X_val, y_train, y_val]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B2YL53QHGcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pipeline to encode, scale, split \n",
        "#if no kwargs are supplied, will only transform data\n",
        "#y = target vector - is optional but required to run split function\n",
        "#dropNA = True - dropNA for df or both df and y\n",
        "#split_data = True - perform train test split and return list of split data\n",
        "\n",
        "def pipeline(df, **kwargs):\n",
        "  target_supplied = False\n",
        "  \n",
        "  #copy and transform data\n",
        "  x = pd.DataFrame(transform(df.copy()))\n",
        "  \n",
        "  #check kwargs data for functions inputs\n",
        "  function = {'dropNA': False, 'split_data': False}\n",
        "  for key in function:\n",
        "    if key in kwargs and kwargs[key]:\n",
        "      function[key] = True\n",
        "  \n",
        "  #if a target vector is supplied, store a copy in Y\n",
        "  if 'y' in kwargs:\n",
        "    Y = kwargs['y'].copy()\n",
        "    target_supplied = True\n",
        "    \n",
        "  #if dropNA is requested, run function dropNA with target vector\n",
        "  if function['dropNA'] and target_supplied:\n",
        "    x,Y = dropNA(x, y = Y)\n",
        "  #if dropNA is requested with no target data, just update X\n",
        "  elif function['dropNA'] and not target_supplied:\n",
        "    x = dropNA(x)\n",
        "    \n",
        "  #if split data is requested, run function split_data(requires target to be true)\n",
        "  if function['split_data'] and target_supplied:\n",
        "    return split_data(x,Y)\n",
        "  \n",
        "  if target_supplied:\n",
        "    return x,Y\n",
        "  else:\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_bQb-pv-txY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test and score each model\n",
        "def model_score(model, data):\n",
        "  X_train = data[0] \n",
        "  X_val = data[1]\n",
        "  y_train = data[2]\n",
        "  y_val = data[3]\n",
        "  \n",
        "  model.fit(X_train,y_train)\n",
        "  y_pred = model.predict(X_val)\n",
        "  \n",
        "  return accuracy_score(y_val, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCiURsD-_XHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d02a1ec3-ada1-4096-eeb8-0bf620c20387"
      },
      "source": [
        "#run dfs through pipeline\n",
        "data = pipeline(X, y = Y, dropNA = True, split_data = True)\n",
        "\n",
        "#instantiate models\n",
        "dt = DecisionTreeClassifier()\n",
        "gbm = GradientBoostingClassifier()\n",
        "knn = KNeighborsClassifier()\n",
        "rfc = RandomForestClassifier()\n",
        "\n",
        "#get and print scores\n",
        "print(f'Tree - {model_score(dt, data)}')\n",
        "print(f'Boost - {model_score(gbm, data)}')\n",
        "print(f'Neighbor - {model_score(knn, data)}')\n",
        "print(f'Forest - {model_score(rfc, data)}')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tree - 0.7436803770351328\n",
            "Boost - 0.7674592973436161\n",
            "Neighbor - 0.7737789203084833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Forest - 0.797343616109683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WPY2-J-HbD8",
        "colab_type": "text"
      },
      "source": [
        "Its looks like Random Forest will give us a good score right from the start. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41qojULoHiqD",
        "colab_type": "text"
      },
      "source": [
        "##Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWEvKxJMkPlS",
        "colab_type": "text"
      },
      "source": [
        "##Submission\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfck95KRhA2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fetch test data for submission\n",
        "test = pd.read_csv('test_features.csv')\n",
        "sample_submission = pd.read_csv('sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWkHWIGlM8Nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clean and preprocess data\n",
        "test = pipeline(test, dropNA = True)\n",
        "X_pip, Y = pipeline(X, y = Y, dropNA = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-R19_pxnP_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forest = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "forest.fit(X_pip, Y)\n",
        "y_pred = forest.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJsZAg1WkSRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "submission.to_csv('submission-01.csv', index=False)\n",
        "\n",
        "\n",
        "files.download('submission-01.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}